# Word2Vec

## 0. Basics

### what is embedding?

A process to convert word to vector

Typically, map from one word one dimension (token, one-hot encoding) to less dimension, most common tech is word2vec.

Ref: [Blog](https://machinelearningmastery.com/what-are-word-embeddings/):?(TBD)


## 1. Introduction


## 2. Training

