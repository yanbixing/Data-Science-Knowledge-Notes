# Ads Basics

## Business Sense: Factors affect ranking

Ref: [Facebook-ads](https://www.facebook.com/business/news/good-questions-real-answers-how-does-facebook-use-machine-learning-to-deliver-ads)

- Ads can be ranked by "total value" which can be composited from
  - Advertise bid: 
    - how much advertiser are willing to pay
  - Estimated action rate: 
    - The likelihood of a particular person taking the desired action define by advertiser.
    - Generated by machine learning model based on user (who **didn't see the ads**) info, ads info, user-ads interaction info, other info
      - user info: background, in-app behavior, out-of-app behavior
      - ads: category, price, target population, etc.
      - user-ads interaction: content-preference similarities or interaction between similar people and similar products (collaborative filtering)
      - other: **time of the day**
  - Ads quality:
    - Feedback of people who viewing the ads.
    - Generated by machine learning model based on behavior of **user have seen the ads**.
      - Action features: hiding, convert, time_to_stay, bouncing rate (ratio of people who leave immediately.)


## SysDesign Interview

- Ask what is the high level goal?
  - Just action rate
  - Or the value score, should be decomposed to (bid, action rate, quality)
- Ask what is the specific prediction target of our model
  - Action rate: click? conversion?
    - build a model to predict the user's probability of click (action)
    - framework is more like ranking system.
  - Quality score: 
    - build a model to generate predefined quality score based on other user
      - framework is more like collaborative filtering.
    - quality score can be used as a feature for action rate prediction.
      - Or can be used as an individual factor to consider, avoid user-aversion/providing-unfavored-info to annoy user.
- Ask multi-stage or just one? 
  - Multi-stage need to consider different data size/precision requirement on different
  - Multi-stage need ot consider different input feature and output label.
- Ask what is the output label.
- Feature exploration
  - The above features for feature-based models.
  - The user-item matrix (past history) for collaborative filtering
- Models selection:
  - Feature-based model:
    - pointer wise, predict the click prob.
      - Classical or NN, binary classification
    - pairwise (ranking) model, predict the ranking score or just the order.
      - Classical or NN, binary classification
      - Typically NN (RankNet, LambdaNet)
  - Collaborative filtering:
    - user-based: use-similarity weighted * rating scores of the same item from different users.
    - item-based: item-similarity weighted * rating on different items from the same user.
- Evaluation:
  - One position: precision, recall
  - Multiple positions: ranking metrics precision@K, MRR, etc.
  - Rating score: MSE (mean square error)